{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up Spark on your own computer and integrate PySpark with Jupyter Notebook. We can use Spark in two modes:\n",
    "\n",
    "* **Local mode**: the entire Spark application runs on a single machine. You'll use local mode to prototype Spark code on your own computer. (This is the easier setup.)\n",
    "* **Cluster mode**: the Spark application runs across multiple machines. You'll use cluster mode when you want to run your Spark application across multiple machines in a cloud environment like Amazon Web Services, Microsoft Azure, or Digital Ocean.\n",
    "\n",
    "We'll cover the instructions for installing Spark in local mode on Windows, Mac, and Linux. We'll cover how to install Spark in cluster mode in the data engineering track.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
